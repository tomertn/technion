{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YVw7q0-rMwFZ",
        "Cnu-gbXHj2Vm",
        "JvRQHu3sAV1j",
        "AQ4y4jYbotzK",
        "jkOHMsjg3SLm",
        "0SxYoq0R81be"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVw7q0-rMwFZ",
        "colab_type": "text"
      },
      "source": [
        "# Globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W19yL3-2N3id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install  area\n",
        "import pdb\n",
        "imgsFilePath = \"gdrive/My Drive/projectA/Data/training_imagery/\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#for general class:\n",
        "# testFilename=\"gdrive/My Drive/projectA/Data/test_w_n.csv\"\n",
        "# annotationFilename = \"gdrive/My Drive/projectA/Data/train_w_n.csv\"\n",
        "\n",
        "#for subclass:\n",
        "testFilename=\"gdrive/My Drive/projectA/Data/test_without_zoomout_large_vehicles.csv\"\n",
        "annotationFilename = \"gdrive/My Drive/projectA/Data/train_without_zoomout_large_vehicles.csv\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLnbyPuF3Z2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crop_rect(img, rect):\n",
        "    # get the parameter of the small rectangle\n",
        "    center = rect[0]\n",
        "    size = rect[1]\n",
        "    angle = rect[2]\n",
        "    center, size = tuple(map(int, center)), tuple(map(int, size))\n",
        "\n",
        "    # get row and col num in img\n",
        "    height, width = img.shape[0], img.shape[1]\n",
        "\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1)\n",
        "    img_rot = cv2.warpAffine(img, M, (width, height))\n",
        "\n",
        "    img_crop = cv2.getRectSubPix(img_rot, size, center)\n",
        "\n",
        "    return img_crop, img_rot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK9j8VEMuY0z",
        "colab_type": "text"
      },
      "source": [
        "#Big-Small"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVhz-ONqvL_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "from area import area\n",
        "drive.mount('/content/gdrive')\n",
        "label_map = {\n",
        "    'bus':0, 'cement mixer': 1, 'crane truck': 2, 'dedicated agricultural vehicle': 3,\n",
        "    'hatchback': 4, 'jeep':5, 'light truck':6, 'minibus':7, 'minivan':8, 'pickup':9,\n",
        "    'prime mover': 10, 'sedan':11, 'tanker':12, 'truck': 13, 'van': 14\n",
        "}\n",
        "\n",
        "def prepareInputs(annotationFilename, imgsFilePath = \"gdrive/My Drive/projectA/Data/training_imagery/\",\n",
        "                  sampleShape = (128,128), maxSetSize = 100000):\n",
        "    print(\"Start preproccesing\")\n",
        "    annotationDB = pd.read_csv(annotationFilename)\n",
        "    nRecords = annotationDB.shape[0]\n",
        "    Samples = {};\n",
        "    Labels = {};\n",
        "    area_per_size = []; maxDistances =[]; i=0\n",
        "    numOfSamples = 0\n",
        "    invalids = 0  \n",
        "    for recIndex in range(nRecords):\n",
        "        if maxSetSize < 0 or numOfSamples < maxSetSize:\n",
        "            imgID = annotationDB.loc[recIndex, 'image_id']\n",
        "            objectBoundingBox = abs(np.array([[annotationDB.loc[recIndex, 'p1_x'], annotationDB.loc[recIndex, 'p_1y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p2_x'], annotationDB.loc[recIndex, 'p2_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p3_x'], annotationDB.loc[recIndex, 'p3_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p4_x'], annotationDB.loc[recIndex, 'p4_y']]]))\n",
        "            imgFile = glob.glob(os.path.join(imgsFilePath, str(int(imgID)) + \".*\"))\n",
        "#             pdb.set_trace()\n",
        "            if len(imgFile) == 1:\n",
        "                img = cv2.imread(imgFile[0],cv2.IMREAD_COLOR)  # now img is 3-dim array\n",
        "                cnt = objectBoundingBox.astype(int)\n",
        "                patch = img[int(np.min(objectBoundingBox[:,1])):int(np.max(objectBoundingBox[:,1])),\n",
        "                        int(np.min(objectBoundingBox[:,0])):int(np.max(objectBoundingBox[:,0]))]\n",
        "                patchShape = patch.shape \n",
        "                if patchShape[0] > 0 and patchShape[1] > 0:\n",
        "                    rect = cv2.minAreaRect(cnt)\n",
        "                    box = cv2.boxPoints(rect)\n",
        "                    box = np.int0(box)\n",
        "                    cv2.drawContours(img, [box], 0, (0, 10, 0), 0)\n",
        "                    img_crop, img_rot = crop_rect(img, rect)\n",
        "                    patch = img_crop\n",
        "                    patchShape =  patch.shape\n",
        "                  \n",
        "                    desired_size = sampleShape[0]\n",
        "                    old_size = patchShape\n",
        "                    ratio = float(sampleShape[0])/max(old_size)\n",
        "                    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "                    old_sample = cv2.resize(patch, (new_size[1], new_size[0]))\n",
        "                    delta_w = desired_size - new_size[1]\n",
        "                    delta_h = desired_size - new_size[0]\n",
        "                    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "                    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "                    color = [0, 0, 0]\n",
        "                    sample = cv2.copyMakeBorder(old_sample, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                        value=color)\n",
        "                    Samples[annotationDB.loc[recIndex, 'tag_id']] = sample\n",
        "                    Labels[annotationDB.loc[recIndex, 'tag_id']] = label_map[annotationDB.loc[recIndex, 'sub_class']]\n",
        "                    numOfSamples += 1\n",
        "                    if Labels[annotationDB.loc[recIndex, 'tag_id']] not in [4,11]:\n",
        "                      img_90 = np.rot90(sample)\n",
        "                      new_tag =annotationDB.loc[recIndex, 'tag_id']*10+1\n",
        "                      Samples[new_tag] = img_90\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      img_180 = np.rot90(img_90)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = img_180\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      img_270 = np.rot90(img_180)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = img_270\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img = cv2.flip( sample, 1 )\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_90 = np.rot90(vertical_img)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_90\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_180 = np.rot90(vertical_img_90)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_180\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_270 = np.rot90(vertical_img_180)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_270\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      numOfSamples += 7\n",
        "\n",
        "                else:\n",
        "                    print(\"Invalid image\\n\")\n",
        "                    print (patchShape , \"no. : \" , recIndex , \"tag: \" , annotationDB.loc[recIndex, 'tag_id'])\n",
        "                    invalids += 1\n",
        "            else:\n",
        "                pdb.set_trace()\n",
        "                print(\"Image file missing!\\n\")\n",
        "            i+=1\n",
        "            if i%500 == 0:\n",
        "              print(\"Finished image no. : \" , i)\n",
        "    print(\"Finished! valids: \" , len(Samples) , \"invalids: \" , invalids)\n",
        "    return [Samples, Labels, numOfSamples ]#, area_per_size,maxDistances]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYN3dMmYxl9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def prepareInputs_test(annotationFilename, imgsFilePath = \"gdrive/My Drive/projectA/Data/training_imagery/\",\n",
        "                  sampleShape = (128,128), maxSetSize = 10000):\n",
        "    print(\"Start preproccesing\")\n",
        "    annotationDB = pd.read_csv(annotationFilename)\n",
        "    nRecords = annotationDB.shape[0]\n",
        "    Samples = {};\n",
        "    Labels = {};\n",
        "    area_per_size = []; maxDistances =[]; i=0\n",
        "    numOfSamples = 0\n",
        "    invalids = 0  \n",
        "    for recIndex in range(nRecords):\n",
        "        if maxSetSize < 0 or numOfSamples < maxSetSize:\n",
        "            imgID = annotationDB.loc[recIndex, 'image_id']\n",
        "            objectBoundingBox = abs(np.array([[annotationDB.loc[recIndex, 'p1_x'], annotationDB.loc[recIndex, 'p_1y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p2_x'], annotationDB.loc[recIndex, 'p2_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p3_x'], annotationDB.loc[recIndex, 'p3_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p4_x'], annotationDB.loc[recIndex, 'p4_y']]]))\n",
        "            imgFile = glob.glob(os.path.join(imgsFilePath, str(int(imgID)) + \".*\"))\n",
        "            if len(imgFile) == 1:\n",
        "                img = cv2.imread(imgFile[0],cv2.IMREAD_COLOR)  # now img is 3-dim array\n",
        "                # TODO: check for image boundaries\n",
        "                cnt = objectBoundingBox.astype(int)\n",
        "                patch = img[int(np.min(objectBoundingBox[:,1])):int(np.max(objectBoundingBox[:,1])),\n",
        "                        int(np.min(objectBoundingBox[:,0])):int(np.max(objectBoundingBox[:,0]))]\n",
        "                patchShape = patch.shape \n",
        "                if patchShape[0] > 0 and patchShape[1] > 0:\n",
        "                    rect = cv2.minAreaRect(cnt)\n",
        "                    box = cv2.boxPoints(rect)\n",
        "                    box = np.int0(box)\n",
        "                    cv2.drawContours(img, [box], 0, (0, 10, 0), 0)\n",
        "                    img_crop, img_rot = crop_rect(img, rect)\n",
        "                    patch = img_crop\n",
        "                    patchShape =  patch.shape\n",
        "                    \n",
        "                    desired_size = sampleShape[0]\n",
        "                    old_size = patchShape\n",
        "                    ratio = float(sampleShape[0])/max(old_size)\n",
        "                    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "                    old_sample = cv2.resize(patch, (new_size[1], new_size[0]))\n",
        "                    delta_w = desired_size - new_size[1]\n",
        "                    delta_h = desired_size - new_size[0]\n",
        "                    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "                    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "                    color = [0, 0, 0]\n",
        "                    sample = cv2.copyMakeBorder(old_sample, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                        value=color)\n",
        "                    Samples[annotationDB.loc[recIndex, 'tag_id']] = sample\n",
        "                    Labels[annotationDB.loc[recIndex, 'tag_id']] = label_map[annotationDB.loc[recIndex, 'sub_class']]\n",
        "                    numOfSamples += 1\n",
        "                    \n",
        "\n",
        "                else:\n",
        "                    print(\"Invalid image\\n\")\n",
        "                    print (patchShape , \"no. : \" , recIndex , \"tag: \" , annotationDB.loc[recIndex, 'tag_id'])\n",
        "                    invalids += 1\n",
        "            else:\n",
        "                pdb.set_trace()\n",
        "                print(\"Image file missing!\\n\")\n",
        "            i+=1\n",
        "            if i%500 == 0:\n",
        "              print(\"Finished image no. : \" , i)\n",
        "    print(\"Finished! valids: \" , len(Samples) , \"invalids: \" , invalids)\n",
        "    return [Samples, Labels, numOfSamples ]#, area_per_size,maxDistances]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELbZgKaxztQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''dataset preperation for subclss problem'''\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "\n",
        "class DataSet_train(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()), self.target[index]\n",
        "      \n",
        "class DataSet_test(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs_test(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()), self.target[index]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAx_C7Ma0tz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_data = DataSet_train(annotationFilename)\n",
        "batch_size = 100\n",
        "my_loader = data.DataLoader(my_data,batch_size=batch_size,shuffle=True,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaXh1y3D0vMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = DataSet_test(testFilename)\n",
        "test_loader = data.DataLoader(test_data,batch_size=batch_size,shuffle=False,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C1TsYlQAJ0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''model definition'''\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "weights = torch.Tensor([1.,1.,1.,1.,3.,2.,2.,2.,2.,1.4,3.5,1.8,1.,1.4,2.])\n",
        "weights = weights.to(device)\n",
        "model = models.resnext50_32x4d(pretrained=True)\n",
        "model.fc = nn.Linear(2048, 15)\n",
        "model = model.to(device)\n",
        "criterium = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4,weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWNdrCm5IgXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loader2 = my_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiNa68Z4CJ08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Training'''\n",
        "'''TODO: try train in balanced set by augment only big cars'''\n",
        "\n",
        "for epoch in range(100):\n",
        "  print('Starting epoch number: ',epoch)\n",
        "  ################## evaluation (testing) section:     ############\n",
        "  if epoch > 0 :\n",
        "    cnt_of_success = np.zeros(15,)\n",
        "    sums = np.zeros(15,)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_of_larges = 0\n",
        "    with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          images = images.permute(0,3,1,2)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels.long().reshape(labels.__len__())).sum().item()\n",
        "          for i in range(len(predicted)):\n",
        "            sums[labels.long().reshape(labels.__len__())[i]]+=1\n",
        "            cnt_of_success[predicted[i]]+=(predicted[i] == labels.long().reshape(labels.__len__())[i]).item()\n",
        "            \n",
        "\n",
        "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
        "    print(correct , \"  \" , total)\n",
        "    print(cnt_of_success/(sums+1e-7))\n",
        "    print(\"predicted: \", cnt_of_success)\n",
        "    print(\"sum of objects: \", sums)\n",
        "    if (100 * correct / total) > 95:\n",
        "      break\n",
        "  ##################################################################\n",
        "  \n",
        "  ######################### Training section:     ##################\n",
        "  for k, (data, label) in enumerate(my_loader):\n",
        "      # Definition of inputs as variables for the net.\n",
        "      # requires_grad is set False because we do not need to compute the \n",
        "      # derivative of the inputs\n",
        "      data   = Variable(data,requires_grad=False)\n",
        "      label = Variable(label.long(),requires_grad=False)\n",
        "      data = data.permute(0,3,1,2)\n",
        "      data = data.to(device)\n",
        "      label = label.to(device)\n",
        "      # Set gradient to 0.\n",
        "      optimizer.zero_grad()\n",
        "      # Feed forward.\n",
        "      pred = model(data)\n",
        "      pred = pred.to(device)\n",
        "      # Loss calculation.\n",
        "      loss = criterium(pred,label.view(-1))\n",
        "      # Gradient calculation.\n",
        "      loss.backward()\n",
        "\n",
        "      # Print loss every 10 iterations.\n",
        "      if k%100==0:\n",
        "          print('Loss {:.4f} at iter {:d}'.format(loss.item(),k))\n",
        "          \n",
        "\n",
        "      # Model weight modification based on the optimizer. \n",
        "      optimizer.step()\n",
        "   ##################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnu-gbXHj2Vm",
        "colab_type": "text"
      },
      "source": [
        "# One Net - all features | large vehicles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4C-rRL8l-W-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_labels(annotationDB , recIndex):\n",
        "  label = []\n",
        "  label.append(np.maximum(annotationDB.loc[recIndex, 'open_cargo_area'], 0))\n",
        "  label.append(np.maximum(annotationDB.loc[recIndex, 'wrecked'], 0))\n",
        "  label.append(np.maximum(annotationDB.loc[recIndex, 'flatbed'], 0))\n",
        "  label.append(np.maximum(annotationDB.loc[recIndex, 'ladder'], 0))\n",
        "  label.append(np.maximum(annotationDB.loc[recIndex, 'enclosed_box'], 0))\n",
        "  label.append(np.maximum(annotationDB.loc[recIndex, 'soft_shell_box'], 0))\n",
        "  label.append(np.maximum(annotationDB.loc[recIndex, 'harnessed_to_a_cart'], 0))\n",
        "  return label\n",
        "\n",
        "\n",
        "testFilename=\"gdrive/My Drive/projectA/Data/test_without_zoomout_large_vehicles.csv\"\n",
        "annotationFilename = \"gdrive/My Drive/projectA/Data/train_without_zoomout_large_vehicles.csv\"\n",
        "\n",
        "def prepareInputs(annotationFilename, imgsFilePath = \"gdrive/My Drive/projectA/Data/training_imagery/\",\n",
        "                  sampleShape = (128,128), maxSetSize = 10000):\n",
        "    print(\"Start preproccesing\")\n",
        "    annotationDB = pd.read_csv(annotationFilename)\n",
        "    nRecords = annotationDB.shape[0]\n",
        "    Samples = {};\n",
        "    Labels = {};\n",
        "    area_per_size = []; maxDistances =[]; i=0\n",
        "    numOfSamples = 0\n",
        "    invalids = 0  \n",
        "    for recIndex in range(nRecords):\n",
        "        if maxSetSize < 0 or numOfSamples < maxSetSize:\n",
        "            imgID = annotationDB.loc[recIndex, 'image_id']\n",
        "            objectBoundingBox = (np.array([[annotationDB.loc[recIndex, 'p1_x'], annotationDB.loc[recIndex, 'p_1y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p2_x'], annotationDB.loc[recIndex, 'p2_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p3_x'], annotationDB.loc[recIndex, 'p3_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p4_x'], annotationDB.loc[recIndex, 'p4_y']]]))\n",
        "            for i,point in enumerate(objectBoundingBox):\n",
        "              for j,coord in enumerate(point):\n",
        "                if coord < 0:\n",
        "                  objectBoundingBox[i][j] = 0\n",
        "                  \n",
        "            imgFile = glob.glob(os.path.join(imgsFilePath, str(int(imgID)) + \".*\"))\n",
        "            if len(imgFile) == 1:\n",
        "                img = cv2.imread(imgFile[0],cv2.IMREAD_COLOR)  # now img is 3-dim array\n",
        "                # TODO: check for image boundaries\n",
        "                cnt = objectBoundingBox.astype(int)\n",
        "                patch = img[int(np.min(objectBoundingBox[:,1])):int(np.max(objectBoundingBox[:,1])),\n",
        "                        int(np.min(objectBoundingBox[:,0])):int(np.max(objectBoundingBox[:,0]))]\n",
        "                patchShape = patch.shape \n",
        "                if patchShape[0] > 0 and patchShape[1] > 0:\n",
        "                    rect = cv2.minAreaRect(cnt)\n",
        "                    box = cv2.boxPoints(rect)\n",
        "                    box = np.int0(box)\n",
        "                    cv2.drawContours(img, [box], 0, (0, 10, 0), 0)\n",
        "                    img_crop, img_rot = crop_rect(img, rect)\n",
        "                    patch = img_crop\n",
        "                    patchShape =  patch.shape\n",
        "                    \n",
        "                    desired_size = sampleShape[0]\n",
        "                    old_size = patchShape\n",
        "                    ratio = float(sampleShape[0])/max(old_size)\n",
        "                    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "                    old_sample = cv2.resize(patch, (new_size[1], new_size[0]))\n",
        "                    delta_w = desired_size - new_size[1]\n",
        "                    delta_h = desired_size - new_size[0]\n",
        "                    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "                    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "                    color = [0, 0, 0]\n",
        "                    sample = cv2.copyMakeBorder(old_sample, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                        value=color)\n",
        "                    Samples[annotationDB.loc[recIndex, 'tag_id']] = sample\n",
        "                    \n",
        "                    Labels[annotationDB.loc[recIndex, 'tag_id']] = get_labels(annotationDB , recIndex)\n",
        "                    numOfSamples += 1\n",
        "                    \n",
        "                    if annotationDB.loc[recIndex, 'general_class'] == 1:\n",
        "                      img_90 = np.rot90(sample)\n",
        "                      new_tag =annotationDB.loc[recIndex, 'tag_id']*10+1\n",
        "                      Samples[new_tag] = img_90\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      img_180 = np.rot90(img_90)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = img_180\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      img_270 = np.rot90(img_180)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = img_270\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img = cv2.flip( sample, 1 )\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_90 = np.rot90(vertical_img)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_90\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_180 = np.rot90(vertical_img_90)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_180\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_270 = np.rot90(vertical_img_180)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_270\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      numOfSamples += 7\n",
        "\n",
        "                else:\n",
        "                    print(\"Invalid image\\n\")\n",
        "                    print (patchShape , \"no. : \" , recIndex , \"tag: \" , annotationDB.loc[recIndex, 'tag_id'])\n",
        "                    invalids += 1\n",
        "            else:\n",
        "                pdb.set_trace()\n",
        "                print(\"Image file missing!\\n\")\n",
        "            i+=1\n",
        "            if i%300 == 0:\n",
        "              print(\"Finished image no. : \" , i)\n",
        "    print(\"Finished! valids: \" , len(Samples) , \"invalids: \" , invalids)\n",
        "    return [Samples, Labels, numOfSamples ]#, area_per_size,maxDistances]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZJNNfJEmLXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''dataset preperation for subclss problem'''\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "\n",
        "class DataSet_train(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()), torch.Tensor(self.target[index].copy())\n",
        "      \n",
        "class DataSet_test(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()), torch.Tensor(self.target[index].copy())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHWgHEbmmZrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_data = DataSet_train(annotationFilename)\n",
        "batch_size = 50\n",
        "my_loader = data.DataLoader(my_data,batch_size=batch_size,shuffle=True,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt_tCrBKmdhF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = DataSet_test(testFilename)\n",
        "batch_size = 50\n",
        "test_loader = data.DataLoader(test_data,batch_size=batch_size,shuffle=False,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fBSYuwlmgo9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''model definition'''\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "\n",
        "model.fc = nn.Linear(2048, 7)\n",
        "\n",
        "model = model.to(device)\n",
        "criterium = nn.CrossEntropyLoss()\n",
        "criterium = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4,weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuEQGMnGm-E2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PliEKxoHmzxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Training'''\n",
        "'''TODO: try train in balanced set by augment only big cars'''\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "for epoch in range(100):\n",
        "  print('Starting epoch number: ',epoch)\n",
        "  ################## evaluation (testing) section:     ############\n",
        "  if epoch >= 0 :\n",
        "    correct_tot = np.zeros(7,)\n",
        "    total_tot = np.zeros(7,)\n",
        "    correct_tot1 = np.zeros(7,)\n",
        "    total_tot1 = np.zeros(7,)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    correct_1 = 0\n",
        "    total_1 = 0\n",
        "    num_of_larges = 0\n",
        "    with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          images = images.permute(0,3,1,2)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          predicted = torch.round(outputs.data+0.35)\n",
        "          for i,line in enumerate(labels):\n",
        "            for j,label in enumerate(line):\n",
        "               total_tot[j] += 1\n",
        "               correct_tot[j] += (predicted[i,j] == label).item()\n",
        "               if label == 1:\n",
        "                  total_tot1[j] += 1\n",
        "                  correct_tot1[j] += (predicted[i,j] == label).item()\n",
        "                  total_1 +=1\n",
        "                  correct_1 += (predicted[i,j] == label).item()\n",
        "          total += (labels.size(0) * labels.size(1) ) \n",
        "          correct += (predicted == labels).sum().item()            \n",
        "    print('Accuracy of the network on the 1795 test images: %d %%' % (100 * correct / total))\n",
        "    print(correct , \"  \" , total)\n",
        "    print('Accuracy of the network on the 1 class only: %d %%' % (100 * correct_1 / total_1))\n",
        "    print(correct_1 , \"  \" , total_1)\n",
        "    if (correct + correct_1 > best) and ((100 * correct / total) >= 93 and  (100 * correct_1 / total_1) >= 87 ):\n",
        "      best = correct + correct_1\n",
        "      path = \"gdrive/My Drive/projectA/Models/all_features_large_model_resnet\"\n",
        "      torch.save(model, path)\n",
        "      print(\"model saved...\")\n",
        "    for i in range(7):\n",
        "      print('Accuracy of the network on the ' ,i,' class: %d %%' % (100 * correct_tot[i] / float(total_tot[i] + 1e-7)))\n",
        "      print(correct_tot[i] , \"  \" , total_tot[i])\n",
        "      print('Accuracy of the network on the ' ,i,' class, only 1: %d %%' % (100 * correct_tot1[i] / float(total_tot1[i] + 1e-7)))\n",
        "      print(correct_tot1[i] , \"  \" , total_tot1[i])\n",
        "\n",
        "     \n",
        "  ##################################################################\n",
        "\n",
        "  ######################### Training section:     ##################\n",
        "  for k, (data, label) in enumerate(my_loader):\n",
        "      # Definition of inputs as variables for the net.\n",
        "      # requires_grad is set False because we do not need to compute the \n",
        "      # derivative of the inputs\n",
        "      data   = Variable(data,requires_grad=False)\n",
        "      label = Variable(label,requires_grad=False)\n",
        "      data = data.permute(0,3,1,2)\n",
        "      data = data.to(device)\n",
        "      label = label.to(device)\n",
        "      # Set gradient to 0.\n",
        "      optimizer.zero_grad()\n",
        "      # Feed forward.\n",
        "      pred = model(data)\n",
        "      pred = pred.to(device)\n",
        "#       print(pred)\n",
        "#       print(label.long())\n",
        "      # Loss calculation.\n",
        "      loss = criterium(pred,label)\n",
        "      # Gradient calculation.\n",
        "      loss.backward()\n",
        "\n",
        "      # Print loss every 10 iterations.\n",
        "      if k%30==0:\n",
        "          print('Loss {:.4f} at iter {:d}'.format(loss.item(),k))\n",
        "          \n",
        "\n",
        "      # Model weight modification based on the optimizer. \n",
        "      optimizer.step()\n",
        "   ##################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAfepKJXO_IL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_resnet = \"gdrive/My Drive/projectA/Models/all_features_model_resnet\"\n",
        "model_resnet = torch.load(path)\n",
        "path_densenet = \"gdrive/My Drive/projectA/Models/all_features_model_densenet\"\n",
        "model_densenet = torch.load(path)\n",
        "path_resnext = \"gdrive/My Drive/projectA/Models/all_features_model_resnext\"\n",
        "model_resnext = torch.load(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWAG7UB8In4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_tot = np.zeros(12,)\n",
        "total_tot = np.zeros(12,)\n",
        "correct_tot1 = np.zeros(12,)\n",
        "total_tot1 = np.zeros(12,)\n",
        "correct = 0\n",
        "total = 0\n",
        "correct_1 = 0\n",
        "total_1 = 0\n",
        "num_of_larges = 0\n",
        "with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          images = images.permute(0,3,1,2)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs_resnet = torch.round(model_resnet(images).data + 0.473)\n",
        "          outputs_resnext = torch.round(model_resnext(images).data + 0.478)\n",
        "          outputs_densenet = torch.round(model_densenet(images).data + 0.476)\n",
        "#           _, predicted = torch.max(outputs.data, 1)\n",
        "          predicted = torch.round( (outputs_densenet + outputs_resnet + outputs_resnext)/float(3) )\n",
        "          for i,line in enumerate(labels):\n",
        "            for j,label in enumerate(line):\n",
        "               total_tot[j] += 1\n",
        "               correct_tot[j] += (predicted[i,j] == label).item()\n",
        "               if label == 1:\n",
        "                  total_tot1[j] += 1\n",
        "                  correct_tot1[j] += (predicted[i,j] == label).item()\n",
        "                  total_1 +=1\n",
        "                  correct_1 += (predicted[i,j] == label).item()\n",
        "          total += (labels.size(0) * labels.size(1) ) \n",
        "          correct += (predicted == labels).sum().item()            \n",
        "#           print(predicted.sum() )\n",
        "print('Accuracy of the network on the 1795 test images: %d %%' % (100 * correct / total))\n",
        "print(correct , \"  \" , total)\n",
        "print('Accuracy of the network on the 1 class only: %d %%' % (100 * correct_1 / total_1))\n",
        "print(correct_1 , \"  \" , total_1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JvRQHu3sAV1j"
      },
      "source": [
        "# One Net - all features | small vehicles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t5IQCF-OAV1l",
        "colab": {}
      },
      "source": [
        "def get_labels(annotationDB , recIndex):\n",
        "  label = []\n",
        "  label.append(np.maximum(annotationDB.loc[recIndex, 'sunroof'], 0))\n",
        "  label.append(np.maximum(annotationDB.loc[recIndex, 'luggage_carrier'], 0))\n",
        "  label.append(np.maximum(annotationDB.loc[recIndex, 'open_cargo_area'], 0))\n",
        "  label.append(np.maximum(annotationDB.loc[recIndex, 'enclosed_cab'], 0))\n",
        "  label.append(np.maximum(annotationDB.loc[recIndex, 'spare_wheel'], 0))\n",
        "  label.append(np.maximum(annotationDB.loc[recIndex, 'wrecked'], 0))\n",
        "  return label\n",
        "\n",
        "testFilename=\"gdrive/My Drive/projectA/Data/test_without_zoomout_small_vehicles.csv\"\n",
        "annotationFilename = \"gdrive/My Drive/projectA/Data/train_without_zoomout_small_vehicles.csv\"\n",
        "\n",
        "def prepareInputs(annotationFilename, imgsFilePath = \"gdrive/My Drive/projectA/Data/training_imagery/\",\n",
        "                  sampleShape = (128,128), maxSetSize = 10000):\n",
        "    print(\"Start preproccesing\")\n",
        "    annotationDB = pd.read_csv(annotationFilename)\n",
        "    nRecords = annotationDB.shape[0]\n",
        "    Samples = {};\n",
        "    Labels = {};\n",
        "    area_per_size = []; maxDistances =[]; i=0\n",
        "    numOfSamples = 0\n",
        "    invalids = 0  \n",
        "    for recIndex in range(nRecords):\n",
        "        if maxSetSize < 0 or numOfSamples < maxSetSize:\n",
        "            imgID = annotationDB.loc[recIndex, 'image_id']\n",
        "            objectBoundingBox = (np.array([[annotationDB.loc[recIndex, 'p1_x'], annotationDB.loc[recIndex, 'p_1y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p2_x'], annotationDB.loc[recIndex, 'p2_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p3_x'], annotationDB.loc[recIndex, 'p3_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p4_x'], annotationDB.loc[recIndex, 'p4_y']]]))\n",
        "            for i,point in enumerate(objectBoundingBox):\n",
        "              for j,coord in enumerate(point):\n",
        "                if coord < 0:\n",
        "                  objectBoundingBox[i][j] = 0\n",
        "                  \n",
        "            imgFile = glob.glob(os.path.join(imgsFilePath, str(int(imgID)) + \".*\"))\n",
        "            if len(imgFile) == 1:\n",
        "                img = cv2.imread(imgFile[0],cv2.IMREAD_COLOR)  # now img is 3-dim array\n",
        "                # TODO: check for image boundaries\n",
        "                cnt = objectBoundingBox.astype(int)\n",
        "                patch = img[int(np.min(objectBoundingBox[:,1])):int(np.max(objectBoundingBox[:,1])),\n",
        "                        int(np.min(objectBoundingBox[:,0])):int(np.max(objectBoundingBox[:,0]))]\n",
        "                patchShape = patch.shape \n",
        "                if patchShape[0] > 0 and patchShape[1] > 0:\n",
        "                    rect = cv2.minAreaRect(cnt)\n",
        "                    box = cv2.boxPoints(rect)\n",
        "                    box = np.int0(box)\n",
        "                    cv2.drawContours(img, [box], 0, (0, 10, 0), 0)\n",
        "                    img_crop, img_rot = crop_rect(img, rect)\n",
        "                    patch = img_crop\n",
        "                    patchShape =  patch.shape\n",
        "                    \n",
        "                    desired_size = sampleShape[0]\n",
        "                    old_size = patchShape\n",
        "                    ratio = float(sampleShape[0])/max(old_size)\n",
        "                    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "                    old_sample = cv2.resize(patch, (new_size[1], new_size[0]))\n",
        "                    delta_w = desired_size - new_size[1]\n",
        "                    delta_h = desired_size - new_size[0]\n",
        "                    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "                    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "                    color = [0, 0, 0]\n",
        "                    sample = cv2.copyMakeBorder(old_sample, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                        value=color)\n",
        "                    Samples[annotationDB.loc[recIndex, 'tag_id']] = sample\n",
        "                    \n",
        "                    Labels[annotationDB.loc[recIndex, 'tag_id']] = get_labels(annotationDB , recIndex)\n",
        "                    numOfSamples += 1\n",
        "                    \n",
        "                    if annotationDB.loc[recIndex, 'general_class'] == 1:\n",
        "                      img_90 = np.rot90(sample)\n",
        "                      new_tag =annotationDB.loc[recIndex, 'tag_id']*10+1\n",
        "                      Samples[new_tag] = img_90\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      img_180 = np.rot90(img_90)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = img_180\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      img_270 = np.rot90(img_180)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = img_270\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img = cv2.flip( sample, 1 )\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_90 = np.rot90(vertical_img)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_90\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_180 = np.rot90(vertical_img_90)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_180\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_270 = np.rot90(vertical_img_180)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_270\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      numOfSamples += 7\n",
        "\n",
        "                else:\n",
        "                    print(\"Invalid image\\n\")\n",
        "                    print (patchShape , \"no. : \" , recIndex , \"tag: \" , annotationDB.loc[recIndex, 'tag_id'])\n",
        "                    invalids += 1\n",
        "            else:\n",
        "                pdb.set_trace()\n",
        "                print(\"Image file missing!\\n\")\n",
        "            i+=1\n",
        "            if i%300 == 0:\n",
        "              print(\"Finished image no. : \" , i)\n",
        "    print(\"Finished! valids: \" , len(Samples) , \"invalids: \" , invalids)\n",
        "    return [Samples, Labels, numOfSamples ]#, area_per_size,maxDistances]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HQeP7dgcAV1p",
        "colab": {}
      },
      "source": [
        "'''dataset preperation for subclss problem'''\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "\n",
        "class DataSet_train(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()), torch.Tensor(self.target[index].copy())\n",
        "      \n",
        "class DataSet_test(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()), torch.Tensor(self.target[index].copy())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GHYLmqsgAV1r",
        "colab": {}
      },
      "source": [
        "my_data = DataSet_train(annotationFilename)\n",
        "batch_size = 100\n",
        "my_loader = data.DataLoader(my_data,batch_size=batch_size,shuffle=True,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yP39acIYAV1u",
        "colab": {}
      },
      "source": [
        "test_data = DataSet_test(testFilename)\n",
        "batch_size = 50\n",
        "test_loader = data.DataLoader(test_data,batch_size=batch_size,shuffle=False,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke5DrsBktNst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_resnet = \"gdrive/My Drive/projectA/Models/all_features_small_model_resnet_final\"\n",
        "model_resnet = torch.load(path_resnet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fZnupWszAV1y",
        "colab": {}
      },
      "source": [
        "'''model definition'''\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "\n",
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "\n",
        "\n",
        "model.fc = nn.Linear(2048, 6)\n",
        "model = model.to(device)\n",
        "criterium = nn.CrossEntropyLoss()\n",
        "criterium = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4,weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d0__EvxpAV12",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JF-kR1tmAV15",
        "colab": {}
      },
      "source": [
        "'''Training'''\n",
        "'''TODO: try train in balanced set by augment only big cars'''\n",
        "model = model_resnet\n",
        "torch.cuda.empty_cache()\n",
        "for epoch in range(100):\n",
        "  print('Starting epoch number: ',epoch)\n",
        "  ################## evaluation (testing) section:     ############\n",
        "  if epoch >= 0 :\n",
        "    correct_tot = np.zeros(6,)\n",
        "    total_tot = np.zeros(6,)\n",
        "    correct_tot1 = np.zeros(6,)\n",
        "    total_tot1 = np.zeros(6,)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    correct_1 = 0\n",
        "    total_1 = 0\n",
        "    num_of_larges = 0\n",
        "    with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          images = images.permute(0,3,1,2)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          predicted = torch.round(outputs.data+0.2)\n",
        "          for i,line in enumerate(labels):\n",
        "            for j,label in enumerate(line):\n",
        "               total_tot[j] += 1\n",
        "               correct_tot[j] += (predicted[i,j] == label).item()\n",
        "               if label == 1:\n",
        "                  total_tot1[j] += 1\n",
        "                  correct_tot1[j] += (predicted[i,j] == label).item()\n",
        "                  total_1 +=1\n",
        "                  correct_1 += (predicted[i,j] == label).item()\n",
        "          total += (labels.size(0) * labels.size(1) ) \n",
        "          correct += (predicted == labels).sum().item()            \n",
        "    print('Accuracy of the network on the 1795 test images: %d %%' % (100 * correct / total))\n",
        "    print(correct , \"  \" , total)\n",
        "    print('Accuracy of the network on the 1 class only: %d %%' % (100 * correct_1 / total_1))\n",
        "    print(correct_1 , \"  \" , total_1)\n",
        "    if (correct + correct_1 > best) and ((100 * correct / total) >= 93 and  (100 * correct_1 / total_1) >= 87 ):\n",
        "      best = correct + correct_1\n",
        "      path = \"gdrive/My Drive/projectA/Models/all_features_small_model_resnet\"\n",
        "      torch.save(model, path)\n",
        "      print(\"model saved...\")\n",
        "    for i in range(6):\n",
        "      print('Accuracy of the network on the ' ,i,' class: %d %%' % (100 * correct_tot[i] / float(total_tot[i] + 1e-7)))\n",
        "      print(correct_tot[i] , \"  \" , total_tot[i])\n",
        "      print('Accuracy of the network on the ' ,i,' class, only 1: %d %%' % (100 * correct_tot1[i] / float(total_tot1[i] + 1e-7)))\n",
        "      print(correct_tot1[i] , \"  \" , total_tot1[i])\n",
        "    if correct > best:\n",
        "      best = correct\n",
        "      path = \"gdrive/My Drive/projectA/Models/all_features_model\"\n",
        "      torch.save(model, path)\n",
        "    if (100 * correct / total) > 95:\n",
        "      break\n",
        "    if (100 * correct / total) > 92 and (100 * correct_1 / total_1)>72:\n",
        "      path = \"gdrive/My Drive/projectA/Models/all_features_model_densenet\"\n",
        "      torch.save(model, path)\n",
        "     \n",
        "  ##################################################################\n",
        "  break\n",
        "  ######################### Training section:     ##################\n",
        "  for k, (data, label) in enumerate(my_loader):\n",
        "      # Definition of inputs as variables for the net.\n",
        "      # requires_grad is set False because we do not need to compute the \n",
        "      # derivative of the inputs\n",
        "      data   = Variable(data,requires_grad=False)\n",
        "      label = Variable(label,requires_grad=False)\n",
        "      data = data.permute(0,3,1,2)\n",
        "      data = data.to(device)\n",
        "      label = label.to(device)\n",
        "      # Set gradient to 0.\n",
        "      optimizer.zero_grad()\n",
        "      # Feed forward.\n",
        "      pred = model(data)\n",
        "      pred = pred.to(device)\n",
        "      # Loss calculation.\n",
        "      loss = criterium(pred,label)\n",
        "      # Gradient calculation.\n",
        "      loss.backward()\n",
        "\n",
        "      # Print loss every 10 iterations.\n",
        "      if k%30==0:\n",
        "          print('Loss {:.4f} at iter {:d}'.format(loss.item(),k))\n",
        "          \n",
        "\n",
        "      # Model weight modification based on the optimizer. \n",
        "      optimizer.step()\n",
        "   ##################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AQ4y4jYbotzK"
      },
      "source": [
        "# sub_class | large vehicles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "27YDWixmotzM",
        "colab": {}
      },
      "source": [
        "label_map = {\n",
        "    'bus':0, 'cement mixer': 1, 'crane truck': 2, 'dedicated agricultural vehicle': 3,\n",
        "    'light truck':4, 'minibus':5,\n",
        "    'prime mover': 6, 'tanker':7, 'truck': 8\n",
        "}\n",
        "\n",
        "def get_labels(annotationDB , recIndex):\n",
        "  label = annotationDB.loc[recIndex, 'sub_class']\n",
        "  return label_map[label]\n",
        "\n",
        "\n",
        "testFilename=\"gdrive/My Drive/projectA/Data/test_without_zoomout_large_vehicles.csv\"\n",
        "annotationFilename = \"gdrive/My Drive/projectA/Data/train_without_zoomout_large_vehicles.csv\"\n",
        "\n",
        "def prepareInputs(annotationFilename, imgsFilePath = \"gdrive/My Drive/projectA/Data/training_imagery/\",\n",
        "                  sampleShape = (128,128), maxSetSize = 10000):\n",
        "    print(\"Start preproccesing\")\n",
        "    annotationDB = pd.read_csv(annotationFilename)\n",
        "    nRecords = annotationDB.shape[0]\n",
        "    Samples = {};\n",
        "    Labels = {};\n",
        "    area_per_size = []; maxDistances =[]; i=0\n",
        "    numOfSamples = 0\n",
        "    invalids = 0  \n",
        "    for recIndex in range(nRecords):\n",
        "        if maxSetSize < 0 or numOfSamples < maxSetSize:\n",
        "            imgID = annotationDB.loc[recIndex, 'image_id']\n",
        "            objectBoundingBox = (np.array([[annotationDB.loc[recIndex, 'p1_x'], annotationDB.loc[recIndex, 'p_1y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p2_x'], annotationDB.loc[recIndex, 'p2_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p3_x'], annotationDB.loc[recIndex, 'p3_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p4_x'], annotationDB.loc[recIndex, 'p4_y']]]))\n",
        "            for i,point in enumerate(objectBoundingBox):\n",
        "              for j,coord in enumerate(point):\n",
        "                if coord < 0:\n",
        "                  objectBoundingBox[i][j] = 0\n",
        "                  \n",
        "            imgFile = glob.glob(os.path.join(imgsFilePath, str(int(imgID)) + \".*\"))\n",
        "            if len(imgFile) == 1:\n",
        "                img = cv2.imread(imgFile[0],cv2.IMREAD_COLOR)  # now img is 3-dim array\n",
        "                cnt = objectBoundingBox.astype(int)\n",
        "                patch = img[int(np.min(objectBoundingBox[:,1])):int(np.max(objectBoundingBox[:,1])),\n",
        "                        int(np.min(objectBoundingBox[:,0])):int(np.max(objectBoundingBox[:,0]))]\n",
        "                patchShape = patch.shape \n",
        "                if patchShape[0] > 0 and patchShape[1] > 0:\n",
        "                    rect = cv2.minAreaRect(cnt)\n",
        "                    box = cv2.boxPoints(rect)\n",
        "                    box = np.int0(box)\n",
        "                    cv2.drawContours(img, [box], 0, (0, 10, 0), 0)\n",
        "                    img_crop, img_rot = crop_rect(img, rect)\n",
        "                    patch = img_crop\n",
        "                    patchShape =  patch.shape\n",
        "                    \n",
        "                    desired_size = sampleShape[0]\n",
        "                    old_size = patchShape\n",
        "                    ratio = float(sampleShape[0])/max(old_size)\n",
        "                    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "                    old_sample = cv2.resize(patch, (new_size[1], new_size[0]))\n",
        "                    delta_w = desired_size - new_size[1]\n",
        "                    delta_h = desired_size - new_size[0]\n",
        "                    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "                    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "                    color = [0, 0, 0]\n",
        "                    sample = cv2.copyMakeBorder(old_sample, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                        value=color)\n",
        "                    Samples[annotationDB.loc[recIndex, 'tag_id']] = sample\n",
        "                    \n",
        "                    Labels[annotationDB.loc[recIndex, 'tag_id']] = get_labels(annotationDB , recIndex)\n",
        "                    numOfSamples += 1\n",
        "                    \n",
        "                    if annotationDB.loc[recIndex, 'general_class'] == 1:\n",
        "                      img_90 = np.rot90(sample)\n",
        "                      new_tag =annotationDB.loc[recIndex, 'tag_id']*10+1\n",
        "                      Samples[new_tag] = img_90\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      img_180 = np.rot90(img_90)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = img_180\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      img_270 = np.rot90(img_180)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = img_270\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img = cv2.flip( sample, 1 )\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_90 = np.rot90(vertical_img)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_90\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_180 = np.rot90(vertical_img_90)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_180\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_270 = np.rot90(vertical_img_180)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_270\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      numOfSamples += 7\n",
        "\n",
        "                else:\n",
        "                    print(\"Invalid image\\n\")\n",
        "                    print (patchShape , \"no. : \" , recIndex , \"tag: \" , annotationDB.loc[recIndex, 'tag_id'])\n",
        "                    invalids += 1\n",
        "            else:\n",
        "                pdb.set_trace()\n",
        "                print(\"Image file missing!\\n\")\n",
        "            i+=1\n",
        "            if i%300 == 0:\n",
        "              print(\"Finished image no. : \" , i)\n",
        "    print(\"Finished! valids: \" , len(Samples) , \"invalids: \" , invalids)\n",
        "    return [Samples, Labels, numOfSamples ]#, area_per_size,maxDistances]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kJMp7KEvotzP",
        "colab": {}
      },
      "source": [
        "'''dataset preperation for subclss problem'''\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "\n",
        "class DataSet_train(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()),self.target[index]\n",
        "      \n",
        "class DataSet_test(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()), self.target[index]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zXOes2gDotzQ",
        "colab": {}
      },
      "source": [
        "my_data = DataSet_train(annotationFilename)\n",
        "batch_size = 50\n",
        "my_loader = data.DataLoader(my_data,batch_size=batch_size,shuffle=True,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vDK4gE-uotzU",
        "colab": {}
      },
      "source": [
        "test_data = DataSet_test(testFilename)\n",
        "batch_size = 50\n",
        "test_loader = data.DataLoader(test_data,batch_size=batch_size,shuffle=False,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "smQ8IgInotzX",
        "colab": {}
      },
      "source": [
        "'''model definition'''\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "model = torchvision.models.resnet152(pretrained=True)\n",
        "\n",
        "model.fc = nn.Linear(2048, 9)\n",
        "model = model.to(device)\n",
        "criterium = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4,weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KnMtN3F0otzZ",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t0ZeE9vbotzb",
        "colab": {}
      },
      "source": [
        "'''Training'''\n",
        "'''TODO: try train in balanced set by augment only big cars'''\n",
        "torch.cuda.empty_cache()\n",
        "for epoch in range(100):\n",
        "  print('Starting epoch number: ',epoch)\n",
        "  ################## evaluation (testing) section:     ############\n",
        "  if epoch >= 0 :\n",
        "    cnt_of_success = np.zeros(9,)\n",
        "    sums = np.zeros(9,)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_of_larges = 0\n",
        "    with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          images = images.permute(0,3,1,2)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels.long().reshape(labels.__len__())).sum().item()\n",
        "          for i in range(len(predicted)):\n",
        "            sums[labels.long().reshape(labels.__len__())[i]]+=1\n",
        "            cnt_of_success[predicted[i]]+=(predicted[i] == labels.long().reshape(labels.__len__())[i]).item()\n",
        "            \n",
        "\n",
        "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
        "    print(correct , \"  \" , total)\n",
        "    if correct > best:\n",
        "      best = correct\n",
        "      path = \"gdrive/My Drive/projectA/Models/sub_class_large_model_resnet\"\n",
        "      torch.save(model, path)\n",
        "      print(\"model saved...\")\n",
        "\n",
        "    if correct > best:\n",
        "      best = correct\n",
        "      path = \"gdrive/My Drive/projectA/Models/all_features_model\"\n",
        "      torch.save(model, path)\n",
        "    if (100 * correct / total) > 95:\n",
        "      break\n",
        "    if (100 * correct / total) > 92 and (100 * correct_1 / total_1)>72:\n",
        "      path = \"gdrive/My Drive/projectA/Models/all_features_model_densenet\"\n",
        "      torch.save(model, path)\n",
        "     \n",
        "  ##################################################################\n",
        "\n",
        "  ######################### Training section:     ##################\n",
        "  for k, (data, label) in enumerate(my_loader):\n",
        "      # Definition of inputs as variables for the net.\n",
        "      # requires_grad is set False because we do not need to compute the \n",
        "      # derivative of the inputs\n",
        "      data   = Variable(data,requires_grad=False)\n",
        "      label = Variable(label,requires_grad=False)\n",
        "      data = data.permute(0,3,1,2)\n",
        "      data = data.to(device)\n",
        "      label = label.to(device)\n",
        "      # Set gradient to 0.\n",
        "      optimizer.zero_grad()\n",
        "      # Feed forward.\n",
        "      pred = model(data)\n",
        "      pred = pred.to(device)\n",
        "\n",
        "      # Loss calculation.\n",
        "      loss = criterium(pred,label.view(-1))\n",
        "      # Gradient calculation.\n",
        "      loss.backward()\n",
        "\n",
        "      # Print loss every 10 iterations.\n",
        "      if k%30==0:\n",
        "          print('Loss {:.4f} at iter {:d}'.format(loss.item(),k))\n",
        "          \n",
        "\n",
        "      # Model weight modification based on the optimizer. \n",
        "      optimizer.step()\n",
        "   ##################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OWyQ4dXSotzd",
        "colab": {}
      },
      "source": [
        "path_resnet = \"gdrive/My Drive/projectA/Models/all_features_model_resnet\"\n",
        "model_resnet = torch.load(path)\n",
        "path_densenet = \"gdrive/My Drive/projectA/Models/all_features_model_densenet\"\n",
        "model_densenet = torch.load(path)\n",
        "path_resnext = \"gdrive/My Drive/projectA/Models/all_features_model_resnext\"\n",
        "model_resnext = torch.load(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AkuVzCBuotzg",
        "colab": {}
      },
      "source": [
        "correct_tot = np.zeros(12,)\n",
        "total_tot = np.zeros(12,)\n",
        "correct_tot1 = np.zeros(12,)\n",
        "total_tot1 = np.zeros(12,)\n",
        "correct = 0\n",
        "total = 0\n",
        "correct_1 = 0\n",
        "total_1 = 0\n",
        "num_of_larges = 0\n",
        "with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          images = images.permute(0,3,1,2)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs_resnet = torch.round(model_resnet(images).data + 0.473)\n",
        "          outputs_resnext = torch.round(model_resnext(images).data + 0.478)\n",
        "          outputs_densenet = torch.round(model_densenet(images).data + 0.476)\n",
        "#           _, predicted = torch.max(outputs.data, 1)\n",
        "          predicted = torch.round( (outputs_densenet + outputs_resnet + outputs_resnext)/float(3) )\n",
        "          for i,line in enumerate(labels):\n",
        "            for j,label in enumerate(line):\n",
        "               total_tot[j] += 1\n",
        "               correct_tot[j] += (predicted[i,j] == label).item()\n",
        "               if label == 1:\n",
        "                  total_tot1[j] += 1\n",
        "                  correct_tot1[j] += (predicted[i,j] == label).item()\n",
        "                  total_1 +=1\n",
        "                  correct_1 += (predicted[i,j] == label).item()\n",
        "          total += (labels.size(0) * labels.size(1) ) \n",
        "          correct += (predicted == labels).sum().item()            \n",
        "#           print(predicted.sum() )\n",
        "print('Accuracy of the network on the 1795 test images: %d %%' % (100 * correct / total))\n",
        "print(correct , \"  \" , total)\n",
        "print('Accuracy of the network on the 1 class only: %d %%' % (100 * correct_1 / total_1))\n",
        "print(correct_1 , \"  \" , total_1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jkOHMsjg3SLm"
      },
      "source": [
        "# sub_class | small vehicles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oe_LhpkC3SLn",
        "colab": {}
      },
      "source": [
        "label_map = {\n",
        "    'hatchback': 0, 'jeep':1, 'minivan':2, 'pickup':3,\n",
        "    'sedan':4, 'van': 5\n",
        "}\n",
        "\n",
        "def get_labels(annotationDB , recIndex):\n",
        "  label = annotationDB.loc[recIndex, 'sub_class']\n",
        "  return label_map[label]\n",
        "\n",
        "\n",
        "testFilename=\"gdrive/My Drive/projectA/Data/red_green.csv\"\n",
        "annotationFilename = \"gdrive/My Drive/projectA/Data/train_without_zoomout_small_vehicles.csv\"\n",
        "\n",
        "def prepareInputs(annotationFilename, imgsFilePath = \"gdrive/My Drive/projectA/Data/training_imagery/\",\n",
        "                  sampleShape = (128,128), maxSetSize = 10000):\n",
        "    print(\"Start preproccesing\")\n",
        "    annotationDB = pd.read_csv(annotationFilename)\n",
        "    nRecords = annotationDB.shape[0]\n",
        "    Samples = {};\n",
        "    Labels = {};\n",
        "    area_per_size = []; maxDistances =[]; i=0\n",
        "    numOfSamples = 0\n",
        "    invalids = 0  \n",
        "    for recIndex in range(nRecords):\n",
        "        if annotationDB.loc[recIndex, 'general_class'] == 1:\n",
        "          continue\n",
        "        if maxSetSize < 0 or numOfSamples < maxSetSize:\n",
        "            imgID = annotationDB.loc[recIndex, 'image_id']\n",
        "            objectBoundingBox = (np.array([[annotationDB.loc[recIndex, 'p1_x'], annotationDB.loc[recIndex, 'p_1y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p2_x'], annotationDB.loc[recIndex, 'p2_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p3_x'], annotationDB.loc[recIndex, 'p3_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p4_x'], annotationDB.loc[recIndex, 'p4_y']]]))\n",
        "            for i,point in enumerate(objectBoundingBox):\n",
        "              for j,coord in enumerate(point):\n",
        "                if coord < 0:\n",
        "                  objectBoundingBox[i][j] = 0\n",
        "                  \n",
        "            imgFile = glob.glob(os.path.join(imgsFilePath, str(int(imgID)) + \".*\"))\n",
        "            if len(imgFile) == 1:\n",
        "                img = cv2.imread(imgFile[0],cv2.IMREAD_COLOR)  # now img is 3-dim array\n",
        "                cnt = objectBoundingBox.astype(int)\n",
        "                patch = img[int(np.min(objectBoundingBox[:,1])):int(np.max(objectBoundingBox[:,1])),\n",
        "                        int(np.min(objectBoundingBox[:,0])):int(np.max(objectBoundingBox[:,0]))]\n",
        "                patchShape = patch.shape \n",
        "                if patchShape[0] > 0 and patchShape[1] > 0:\n",
        "                    rect = cv2.minAreaRect(cnt)\n",
        "                    box = cv2.boxPoints(rect)\n",
        "                    box = np.int0(box)\n",
        "                    cv2.drawContours(img, [box], 0, (0, 10, 0), 0)\n",
        "                    img_crop, img_rot = crop_rect(img, rect)\n",
        "                    patch = img_crop\n",
        "                    patchShape =  patch.shape\n",
        "                    \n",
        "                    desired_size = sampleShape[0]\n",
        "                    old_size = patchShape\n",
        "                    ratio = float(sampleShape[0])/max(old_size)\n",
        "                    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "                    old_sample = cv2.resize(patch, (new_size[1], new_size[0]))\n",
        "                    delta_w = desired_size - new_size[1]\n",
        "                    delta_h = desired_size - new_size[0]\n",
        "                    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "                    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "                    color = [0, 0, 0]\n",
        "                    sample = cv2.copyMakeBorder(old_sample, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                        value=color)\n",
        "                    Samples[annotationDB.loc[recIndex, 'tag_id']] = sample\n",
        "                    \n",
        "                    Labels[annotationDB.loc[recIndex, 'tag_id']] = get_labels(annotationDB , recIndex)\n",
        "                    numOfSamples += 1\n",
        "                    \n",
        "                else:\n",
        "                    print(\"Invalid image\\n\")\n",
        "                    print (patchShape , \"no. : \" , recIndex , \"tag: \" , annotationDB.loc[recIndex, 'tag_id'])\n",
        "                    invalids += 1\n",
        "            else:\n",
        "                pdb.set_trace()\n",
        "                print(\"Image file missing!\\n\")\n",
        "            i+=1\n",
        "            if i%30 == 0:\n",
        "              print(\"Finished image no. : \" , i)\n",
        "    print(\"Finished! valids: \" , len(Samples) , \"invalids: \" , invalids)\n",
        "    return [Samples, Labels, numOfSamples ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xhl53Oej3SLr",
        "colab": {}
      },
      "source": [
        "'''dataset preperation for subclss problem'''\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "\n",
        "class DataSet_train(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()),self.target[index]\n",
        "      \n",
        "class DataSet_test(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()), self.target[index]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "km3r1Yzs3SLt",
        "colab": {}
      },
      "source": [
        "my_data = DataSet_train(annotationFilename)\n",
        "batch_size = 50\n",
        "my_loader = data.DataLoader(my_data,batch_size=batch_size,shuffle=True,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V5pTijXX3SLv",
        "colab": {}
      },
      "source": [
        "test_data = DataSet_test(testFilename)\n",
        "batch_size = 50\n",
        "test_loader = data.DataLoader(test_data,batch_size=batch_size,shuffle=False,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-9HJCczp3SLy",
        "colab": {}
      },
      "source": [
        "'''model definition'''\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "\n",
        "model.fc = nn.Linear(2048, 6)\n",
        "model = model.to(device)\n",
        "criterium = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4,weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CrZSBOd63SLz",
        "colab": {}
      },
      "source": [
        "path_resnet = \"gdrive/My Drive/projectA/Models/sub_class_small_model_resnet_final\"\n",
        "model = torch.load(path_resnet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oJm7XtYn3SL2",
        "colab": {}
      },
      "source": [
        "'''Training'''\n",
        "'''TODO: try train in balanced set by augment only big cars'''\n",
        "torch.cuda.empty_cache()\n",
        "for epoch in range(100):\n",
        "  print('Starting epoch number: ',epoch)\n",
        "  ################## evaluation (testing) section:     ############\n",
        "  if epoch >= 0 :\n",
        "    cnt_of_success = np.zeros(6,)\n",
        "    sums = np.zeros(6,)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_of_larges = 0\n",
        "    with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          images = images.permute(0,3,1,2)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          print (predicted)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels.long().reshape(labels.__len__())).sum().item()\n",
        "          for i in range(len(predicted)):\n",
        "            sums[labels.long().reshape(labels.__len__())[i]]+=1\n",
        "            cnt_of_success[predicted[i]]+=(predicted[i] == labels.long().reshape(labels.__len__())[i]).item()\n",
        "            \n",
        "\n",
        "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
        "    print(correct , \"  \" , total)\n",
        "    if correct > best:\n",
        "      best = correct\n",
        "      path = \"gdrive/My Drive/projectA/Models/sub_class_small_model_resnet\"\n",
        "      torch.save(model, path)\n",
        "      print(\"model saved...\")\n",
        "\n",
        "    if correct > best:\n",
        "      best = correct\n",
        "      path = \"gdrive/My Drive/projectA/Models/all_features_model\"\n",
        "      torch.save(model, path)\n",
        "    if (100 * correct / total) > 95:\n",
        "      break\n",
        "    if (100 * correct / total) > 92 and (100 * correct_1 / total_1)>72:\n",
        "      path = \"gdrive/My Drive/projectA/Models/all_features_model_densenet\"\n",
        "      torch.save(model, path)\n",
        "     \n",
        "  ##################################################################\n",
        "  break\n",
        "  ######################### Training section:     ##################\n",
        "  for k, (data, label) in enumerate(my_loader):\n",
        "      # Definition of inputs as variables for the net.\n",
        "      # requires_grad is set False because we do not need to compute the \n",
        "      # derivative of the inputs\n",
        "      data   = Variable(data,requires_grad=False)\n",
        "      label = Variable(label,requires_grad=False)\n",
        "      data = data.permute(0,3,1,2)\n",
        "      data = data.to(device)\n",
        "      label = label.to(device)\n",
        "      # Set gradient to 0.\n",
        "      optimizer.zero_grad()\n",
        "      # Feed forward.\n",
        "      pred = model(data)\n",
        "      pred = pred.to(device)\n",
        "      # Loss calculation.\n",
        "      loss = criterium(pred,label.view(-1))\n",
        "      # Gradient calculation.\n",
        "      loss.backward()\n",
        "\n",
        "      # Print loss every 10 iterations.\n",
        "      if k%30==0:\n",
        "          print('Loss {:.4f} at iter {:d}'.format(loss.item(),k))\n",
        "          \n",
        "\n",
        "      # Model weight modification based on the optimizer. \n",
        "      optimizer.step()\n",
        "   ##################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cSM1kt6W3SL4",
        "colab": {}
      },
      "source": [
        "path_resnet = \"gdrive/My Drive/projectA/Models/all_features_model_resnet\"\n",
        "model_resnet = torch.load(path)\n",
        "path_densenet = \"gdrive/My Drive/projectA/Models/all_features_model_densenet\"\n",
        "model_densenet = torch.load(path)\n",
        "path_resnext = \"gdrive/My Drive/projectA/Models/all_features_model_resnext\"\n",
        "model_resnext = torch.load(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f9e2bc36-5003-474e-db5e-0c9b27672d9b",
        "id": "gN7c55PX3SL7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "correct_tot = np.zeros(12,)\n",
        "total_tot = np.zeros(12,)\n",
        "correct_tot1 = np.zeros(12,)\n",
        "total_tot1 = np.zeros(12,)\n",
        "correct = 0\n",
        "total = 0\n",
        "correct_1 = 0\n",
        "total_1 = 0\n",
        "num_of_larges = 0\n",
        "with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          images = images.permute(0,3,1,2)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs_resnet = torch.round(model_resnet(images).data + 0.473)\n",
        "          outputs_resnext = torch.round(model_resnext(images).data + 0.478)\n",
        "          outputs_densenet = torch.round(model_densenet(images).data + 0.476)\n",
        "#           _, predicted = torch.max(outputs.data, 1)\n",
        "          predicted = torch.round( (outputs_densenet + outputs_resnet + outputs_resnext)/float(3) )\n",
        "          for i,line in enumerate(labels):\n",
        "            for j,label in enumerate(line):\n",
        "               total_tot[j] += 1\n",
        "               correct_tot[j] += (predicted[i,j] == label).item()\n",
        "               if label == 1:\n",
        "                  total_tot1[j] += 1\n",
        "                  correct_tot1[j] += (predicted[i,j] == label).item()\n",
        "                  total_1 +=1\n",
        "                  correct_1 += (predicted[i,j] == label).item()\n",
        "          total += (labels.size(0) * labels.size(1) ) \n",
        "          correct += (predicted == labels).sum().item()            \n",
        "print('Accuracy of the network on the 1795 test images: %d %%' % (100 * correct / total))\n",
        "print(correct , \"  \" , total)\n",
        "print('Accuracy of the network on the 1 class only: %d %%' % (100 * correct_1 / total_1))\n",
        "print(correct_1 , \"  \" , total_1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 1795 test images: 92 %\n",
            "19864    21540\n",
            "Accuracy of the network on the 1 class only: 62 %\n",
            "266    429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CM9cB0KBt5m-"
      },
      "source": [
        "# color | large vehicles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xrgfpcqyt5nC",
        "colab": {}
      },
      "source": [
        "label_map_list = {\n",
        "    0: [0], 1: [1, 6], 2: [2], 3: [1, 2, 3, 4, 5, 6, 7],\n",
        "    4: [4, 5], 5: [4, 5], 6: [6, 7, 1], 7: [6, 7]\n",
        "}\n",
        "\n",
        "label_map = {\n",
        "    'green': 0, 'yellow': 1, 'red': 2, 'other': 3,\n",
        "    'blue': 4, 'black':5, 'white':6, 'silver/grey':7\n",
        "}\n",
        "\n",
        "def get_labels(annotationDB , recIndex):\n",
        "  label = annotationDB.loc[recIndex, 'color']\n",
        "  return label_map[label]\n",
        "\n",
        "\n",
        "testFilename=\"gdrive/My Drive/projectA/Data/test_without_zoomout_large_vehicles.csv\"\n",
        "annotationFilename = \"gdrive/My Drive/projectA/Data/train_without_zoomout_large_vehicles.csv\"\n",
        "\n",
        "def prepareInputs(annotationFilename, imgsFilePath = \"gdrive/My Drive/projectA/Data/training_imagery/\",\n",
        "                  sampleShape = (128,128), maxSetSize = 10000):\n",
        "    print(\"Start preproccesing\")\n",
        "    annotationDB = pd.read_csv(annotationFilename)\n",
        "    nRecords = annotationDB.shape[0]\n",
        "    Samples = {};\n",
        "    Labels = {};\n",
        "    area_per_size = []; maxDistances =[]; i=0\n",
        "    numOfSamples = 0\n",
        "    invalids = 0  \n",
        "    for recIndex in range(nRecords):\n",
        "        if maxSetSize < 0 or numOfSamples < maxSetSize:\n",
        "            imgID = annotationDB.loc[recIndex, 'image_id']\n",
        "            objectBoundingBox = (np.array([[annotationDB.loc[recIndex, 'p1_x'], annotationDB.loc[recIndex, 'p_1y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p2_x'], annotationDB.loc[recIndex, 'p2_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p3_x'], annotationDB.loc[recIndex, 'p3_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p4_x'], annotationDB.loc[recIndex, 'p4_y']]]))\n",
        "            for i,point in enumerate(objectBoundingBox):\n",
        "              for j,coord in enumerate(point):\n",
        "                if coord < 0:\n",
        "                  objectBoundingBox[i][j] = 0\n",
        "                  \n",
        "            imgFile = glob.glob(os.path.join(imgsFilePath, str(int(imgID)) + \".*\"))\n",
        "            if len(imgFile) == 1:\n",
        "                img = cv2.imread(imgFile[0],cv2.IMREAD_COLOR)  # now img is 3-dim array\n",
        "                cnt = objectBoundingBox.astype(int)\n",
        "                patch = img[int(np.min(objectBoundingBox[:,1])):int(np.max(objectBoundingBox[:,1])),\n",
        "                        int(np.min(objectBoundingBox[:,0])):int(np.max(objectBoundingBox[:,0]))]\n",
        "                patchShape = patch.shape \n",
        "                if patchShape[0] > 0 and patchShape[1] > 0:\n",
        "                    rect = cv2.minAreaRect(cnt)\n",
        "                    box = cv2.boxPoints(rect)\n",
        "                    box = np.int0(box)\n",
        "                    cv2.drawContours(img, [box], 0, (0, 10, 0), 0)\n",
        "                    img_crop, img_rot = crop_rect(img, rect)\n",
        "                    patch = img_crop\n",
        "                    patchShape =  patch.shape\n",
        "                    \n",
        "                    desired_size = sampleShape[0]\n",
        "                    old_size = patchShape\n",
        "                    ratio = float(sampleShape[0])/max(old_size)\n",
        "                    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "                    old_sample = cv2.resize(patch, (new_size[1], new_size[0]))\n",
        "                    delta_w = desired_size - new_size[1]\n",
        "                    delta_h = desired_size - new_size[0]\n",
        "                    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "                    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "                    color = [0, 0, 0]\n",
        "                    sample = cv2.copyMakeBorder(old_sample, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                        value=color)\n",
        "                    Samples[annotationDB.loc[recIndex, 'tag_id']] = sample\n",
        "                    \n",
        "                    Labels[annotationDB.loc[recIndex, 'tag_id']] = get_labels(annotationDB , recIndex)\n",
        "                    numOfSamples += 1\n",
        "                    \n",
        "                    if annotationDB.loc[recIndex, 'color'] != 'white':\n",
        "                      img_90 = np.rot90(sample)\n",
        "                      new_tag =annotationDB.loc[recIndex, 'tag_id']*10+1\n",
        "                      Samples[new_tag] = img_90\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      img_180 = np.rot90(img_90)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = img_180\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      img_270 = np.rot90(img_180)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = img_270\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img = cv2.flip( sample, 1 )\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_90 = np.rot90(vertical_img)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_90\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_180 = np.rot90(vertical_img_90)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_180\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      vertical_img_270 = np.rot90(vertical_img_180)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = vertical_img_270\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      numOfSamples += 7\n",
        "\n",
        "                else:\n",
        "                    print(\"Invalid image\\n\")\n",
        "                    print (patchShape , \"no. : \" , recIndex , \"tag: \" , annotationDB.loc[recIndex, 'tag_id'])\n",
        "                    invalids += 1\n",
        "            else:\n",
        "                pdb.set_trace()\n",
        "                print(\"Image file missing!\\n\")\n",
        "            i+=1\n",
        "            if i%300 == 0:\n",
        "              print(\"Finished image no. : \" , i)\n",
        "    print(\"Finished! valids: \" , len(Samples) , \"invalids: \" , invalids)\n",
        "    return [Samples, Labels, numOfSamples ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jSdqjYj1t5nF",
        "colab": {}
      },
      "source": [
        "'''dataset preperation for subclss problem'''\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "\n",
        "class DataSet_train(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()),self.target[index]\n",
        "      \n",
        "class DataSet_test(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()), self.target[index]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BYvAIP96t5nH",
        "colab": {}
      },
      "source": [
        "my_data = DataSet_train(annotationFilename)\n",
        "batch_size = 50\n",
        "my_loader = data.DataLoader(my_data,batch_size=batch_size,shuffle=True,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pPAHKmjKt5nK",
        "colab": {}
      },
      "source": [
        "test_data = DataSet_test(testFilename)\n",
        "batch_size = 50\n",
        "test_loader = data.DataLoader(test_data,batch_size=batch_size,shuffle=False,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VJGfZT99t5nO",
        "colab": {}
      },
      "source": [
        "'''model definition'''\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "weights = torch.Tensor([3.,3.,3.,3.,3.,3.,1.,3.])\n",
        "weights = weights.to(device)\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "model.fc = nn.Linear(512, 8)\n",
        "model = model.to(device)\n",
        "criterium = nn.CrossEntropyLoss(weight=weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4,weight_decay=1e-4)\n",
        "best = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d-9JnsUtt5nQ",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr=1e-5,weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wr7adHZyt5nS",
        "colab": {}
      },
      "source": [
        "'''Training'''\n",
        "'''TODO: try train in balanced set by augment only big cars'''\n",
        "torch.cuda.empty_cache()\n",
        "for epoch in range(500):\n",
        "  print('Starting epoch number: ',epoch)\n",
        "  ################## evaluation (testing) section:     ############\n",
        "  if epoch > 0 :\n",
        "    cnt_of_success = np.zeros(8,)\n",
        "    sums = np.zeros(8,)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_of_larges = 0\n",
        "    with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          images = images.permute(0,3,1,2)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          for i in range(len(predicted)):\n",
        "            correct += (predicted[i].item() in label_map_list[labels.long().reshape(labels.__len__())[i].item()])\n",
        "            sums[labels.long().reshape(labels.__len__())[i]]+=1\n",
        "            \n",
        "\n",
        "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
        "    print(correct , \"  \" , total)\n",
        "\n",
        "    if correct > best:\n",
        "      best = correct\n",
        "      path = \"gdrive/My Drive/projectA/Models/color_large_model_resnet18\"\n",
        "      torch.save(model, path)\n",
        "      print(\"model saved...\")\n",
        "\n",
        "     \n",
        "  ##################################################################\n",
        "\n",
        "  ######################### Training section:     ##################\n",
        "  for k, (data, label) in enumerate(my_loader):\n",
        "      # Definition of inputs as variables for the net.\n",
        "      # requires_grad is set False because we do not need to compute the \n",
        "      # derivative of the inputs\n",
        "      data   = Variable(data,requires_grad=False)\n",
        "      label = Variable(label,requires_grad=False)\n",
        "      data = data.permute(0,3,1,2)\n",
        "      data = data.to(device)\n",
        "      label = label.to(device)\n",
        "      # Set gradient to 0.\n",
        "      optimizer.zero_grad()\n",
        "      # Feed forward.\n",
        "      pred = model(data)\n",
        "      pred = pred.to(device)\n",
        "\n",
        "      # Loss calculation.\n",
        "      loss = criterium(pred,label.view(-1))\n",
        "      # Gradient calculation.\n",
        "      loss.backward()\n",
        "\n",
        "      # Print loss every 10 iterations.\n",
        "      if k%30==0:\n",
        "          print('Loss {:.4f} at iter {:d}'.format(loss.item(),k))\n",
        "          \n",
        "\n",
        "      # Model weight modification based on the optimizer. \n",
        "      optimizer.step()\n",
        "   ##################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_nY57zYst5nU",
        "colab": {}
      },
      "source": [
        "path_resnet = \"gdrive/My Drive/projectA/Models/all_features_model_resnet\"\n",
        "model_resnet = torch.load(path)\n",
        "path_densenet = \"gdrive/My Drive/projectA/Models/all_features_model_densenet\"\n",
        "model_densenet = torch.load(path)\n",
        "path_resnext = \"gdrive/My Drive/projectA/Models/all_features_model_resnext\"\n",
        "model_resnext = torch.load(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K0JC8C0ft5nX",
        "colab": {}
      },
      "source": [
        "correct_tot = np.zeros(12,)\n",
        "total_tot = np.zeros(12,)\n",
        "correct_tot1 = np.zeros(12,)\n",
        "total_tot1 = np.zeros(12,)\n",
        "correct = 0\n",
        "total = 0\n",
        "correct_1 = 0\n",
        "total_1 = 0\n",
        "num_of_larges = 0\n",
        "with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          images = images.permute(0,3,1,2)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs_resnet = torch.round(model_resnet(images).data + 0.473)\n",
        "          outputs_resnext = torch.round(model_resnext(images).data + 0.478)\n",
        "          outputs_densenet = torch.round(model_densenet(images).data + 0.476)\n",
        "          predicted = torch.round( (outputs_densenet + outputs_resnet + outputs_resnext)/float(3) )\n",
        "          for i,line in enumerate(labels):\n",
        "            for j,label in enumerate(line):\n",
        "               total_tot[j] += 1\n",
        "               correct_tot[j] += (predicted[i,j] == label).item()\n",
        "               if label == 1:\n",
        "                  total_tot1[j] += 1\n",
        "                  correct_tot1[j] += (predicted[i,j] == label).item()\n",
        "                  total_1 +=1\n",
        "                  correct_1 += (predicted[i,j] == label).item()\n",
        "          total += (labels.size(0) * labels.size(1) ) \n",
        "          correct += (predicted == labels).sum().item()            \n",
        "print('Accuracy of the network on the 1795 test images: %d %%' % (100 * correct / total))\n",
        "print(correct , \"  \" , total)\n",
        "print('Accuracy of the network on the 1 class only: %d %%' % (100 * correct_1 / total_1))\n",
        "print(correct_1 , \"  \" , total_1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0SxYoq0R81be"
      },
      "source": [
        "# color | small vehicles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_2HbmPf181bf",
        "colab": {}
      },
      "source": [
        "label_map_list = {\n",
        "    0: [0], 1: [1, 6], 2: [2], 3: [1, 2, 3, 4, 5, 6, 7],\n",
        "    4: [4, 5], 5: [4, 5], 6: [6, 7, 1], 7: [6, 7]\n",
        "}\n",
        "\n",
        "label_map = {\n",
        "    'green': 0, 'yellow': 1, 'red': 2, 'other': 3,\n",
        "    'blue': 4, 'black':5, 'white':6, 'silver/grey':7\n",
        "}\n",
        "\n",
        "def get_labels(annotationDB , recIndex):\n",
        "  label = annotationDB.loc[recIndex, 'color']\n",
        "  return label_map[label]\n",
        "\n",
        "\n",
        "testFilename=\"gdrive/My Drive/projectA/Data/test_without_zoomout_small_vehicles.csv\"\n",
        "annotationFilename = \"gdrive/My Drive/projectA/Data/train_without_zoomout_small_vehicles.csv\"\n",
        "\n",
        "def prepareInputs(annotationFilename, imgsFilePath = \"gdrive/My Drive/projectA/Data/training_imagery/\",\n",
        "                  sampleShape = (128,128), maxSetSize = 100000):\n",
        "    print(\"Start preproccesing\")\n",
        "    annotationDB = pd.read_csv(annotationFilename)\n",
        "    nRecords = annotationDB.shape[0]\n",
        "    Samples = {};\n",
        "    Labels = {};\n",
        "    area_per_size = []; maxDistances =[]; i=0\n",
        "    numOfSamples = 0\n",
        "    invalids = 0  \n",
        "    for recIndex in range(nRecords):\n",
        "        if maxSetSize < 0 or numOfSamples < maxSetSize:\n",
        "            imgID = annotationDB.loc[recIndex, 'image_id']\n",
        "            objectBoundingBox = (np.array([[annotationDB.loc[recIndex, 'p1_x'], annotationDB.loc[recIndex, 'p_1y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p2_x'], annotationDB.loc[recIndex, 'p2_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p3_x'], annotationDB.loc[recIndex, 'p3_y']],\n",
        "                                          [annotationDB.loc[recIndex, 'p4_x'], annotationDB.loc[recIndex, 'p4_y']]]))\n",
        "            for i,point in enumerate(objectBoundingBox):\n",
        "              for j,coord in enumerate(point):\n",
        "                if coord < 0:\n",
        "                  objectBoundingBox[i][j] = 0\n",
        "                  \n",
        "            imgFile = glob.glob(os.path.join(imgsFilePath, str(int(imgID)) + \".*\"))\n",
        "            if len(imgFile) == 1:\n",
        "                img = cv2.imread(imgFile[0],cv2.IMREAD_COLOR)  # now img is 3-dim array\n",
        "                cnt = objectBoundingBox.astype(int)\n",
        "                patch = img[int(np.min(objectBoundingBox[:,1])):int(np.max(objectBoundingBox[:,1])),\n",
        "                        int(np.min(objectBoundingBox[:,0])):int(np.max(objectBoundingBox[:,0]))]\n",
        "                patchShape = patch.shape \n",
        "                if patchShape[0] > 0 and patchShape[1] > 0:\n",
        "                    rect = cv2.minAreaRect(cnt)\n",
        "                    box = cv2.boxPoints(rect)\n",
        "                    box = np.int0(box)\n",
        "                    cv2.drawContours(img, [box], 0, (0, 10, 0), 0)\n",
        "                    img_crop, img_rot = crop_rect(img, rect)\n",
        "                    patch = img_crop\n",
        "                    patchShape =  patch.shape\n",
        "                    \n",
        "                    desired_size = sampleShape[0]\n",
        "                    old_size = patchShape\n",
        "                    ratio = float(sampleShape[0])/max(old_size)\n",
        "                    new_size = tuple([int(x*ratio) for x in old_size])\n",
        "                    old_sample = cv2.resize(patch, (new_size[1], new_size[0]))\n",
        "                    delta_w = desired_size - new_size[1]\n",
        "                    delta_h = desired_size - new_size[0]\n",
        "                    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
        "                    left, right = delta_w//2, delta_w-(delta_w//2)\n",
        "                    color = [0, 0, 0]\n",
        "                    sample = cv2.copyMakeBorder(old_sample, top, bottom, left, right, cv2.BORDER_CONSTANT,\n",
        "                        value=color)\n",
        "                    Samples[annotationDB.loc[recIndex, 'tag_id']] = sample\n",
        "                    \n",
        "                    Labels[annotationDB.loc[recIndex, 'tag_id']] = get_labels(annotationDB , recIndex)\n",
        "                    numOfSamples += 1\n",
        "                    \n",
        "                    if annotationDB.loc[recIndex, 'color'] not in ['white','silver/grey']:\n",
        "                      img_90 = np.rot90(sample)\n",
        "                      new_tag =annotationDB.loc[recIndex, 'tag_id']*10+1\n",
        "                      Samples[new_tag] = img_90\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      img_180 = np.rot90(img_90)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = img_180\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      img_270 = np.rot90(img_180)\n",
        "                      new_tag +=1\n",
        "                      Samples[new_tag] = img_270\n",
        "                      Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                      if annotationDB.loc[recIndex, 'color'] not in ['black','blue']:\n",
        "                        vertical_img = cv2.flip( sample, 1 )\n",
        "                        new_tag +=1\n",
        "                        Samples[new_tag] = vertical_img\n",
        "                        Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                        vertical_img_90 = np.rot90(vertical_img)\n",
        "                        new_tag +=1\n",
        "                        Samples[new_tag] = vertical_img_90\n",
        "                        Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                        vertical_img_180 = np.rot90(vertical_img_90)\n",
        "                        new_tag +=1\n",
        "                        Samples[new_tag] = vertical_img_180\n",
        "                        Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                        vertical_img_270 = np.rot90(vertical_img_180)\n",
        "                        new_tag +=1\n",
        "                        Samples[new_tag] = vertical_img_270\n",
        "                        Labels[new_tag] = Labels[annotationDB.loc[recIndex, 'tag_id']]\n",
        "                        numOfSamples += 7\n",
        "                      else:\n",
        "                        numOfSamples += 3\n",
        "\n",
        "                else:\n",
        "                    print(\"Invalid image\\n\")\n",
        "                    print (patchShape , \"no. : \" , recIndex , \"tag: \" , annotationDB.loc[recIndex, 'tag_id'])\n",
        "                    invalids += 1\n",
        "            else:\n",
        "                pdb.set_trace()\n",
        "                print(\"Image file missing!\\n\")\n",
        "            i+=1\n",
        "            if i%300 == 0:\n",
        "              print(\"Finished image no. : \" , i)\n",
        "    print(\"Finished! valids: \" , len(Samples) , \"invalids: \" , invalids)\n",
        "    return [Samples, Labels, numOfSamples ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x1GT-pJa81bi",
        "colab": {}
      },
      "source": [
        "'''dataset preperation for subclss problem'''\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "\n",
        "class DataSet_train(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()),self.target[index]\n",
        "      \n",
        "class DataSet_test(data.Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.DB = pd.read_csv(filename)\n",
        "        data, labels, numOfSamples = prepareInputs(filename)\n",
        "        self.data = list(data.values())\n",
        "        self.target = list(labels.values())\n",
        "        self.n_samples = numOfSamples\n",
        "    \n",
        "    def __len__(self):   # Length of the dataset.\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):   # Function that returns one point and one label.\n",
        "        return torch.Tensor(self.data[index].copy()), self.target[index]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_efGEnis81bl",
        "colab": {}
      },
      "source": [
        "my_data = DataSet_train(annotationFilename)\n",
        "batch_size = 100\n",
        "my_loader = data.DataLoader(my_data,batch_size=batch_size,shuffle=True,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m5Qqb7gG81bo",
        "colab": {}
      },
      "source": [
        "test_data = DataSet_test(testFilename)\n",
        "batch_size = 100\n",
        "test_loader = data.DataLoader(test_data,batch_size=batch_size,shuffle=False,num_workers=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k34crqmO81br",
        "colab": {}
      },
      "source": [
        "'''model definition'''\n",
        "torch.cuda.empty_cache()\n",
        "# device = torch.device(\"cpu\")\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "import torchvision.models as models\n",
        "import torch.optim as optim\n",
        "weights = torch.Tensor([8.,8.,1.5,1.,1.5,1.,1.,1.])\n",
        "weights = weights.to(device)\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "model.fc = nn.Linear(512, 8)\n",
        "model = model.to(device)\n",
        "criterium = nn.CrossEntropyLoss(weight=weights)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4,weight_decay=1e-4)\n",
        "best = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f4__Nycz81bu",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=2e-3,weight_decay=1e-4)\n",
        "path_resnet = \"gdrive/My Drive/projectA/Models/all_features_large_model_resnet\"\n",
        "model = torch.load(path_resnet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wVEwab0A81bw",
        "colab": {}
      },
      "source": [
        "'''Training'''\n",
        "'''TODO: try train in balanced set by augment only big cars'''\n",
        "best = 0\n",
        "torch.cuda.empty_cache()\n",
        "for epoch in range(100):\n",
        "  print('Starting epoch number: ',epoch)\n",
        "  ################## evaluation (testing) section:     ############\n",
        "  if epoch > 0 :\n",
        "    cnt_of_success = np.zeros(8,)\n",
        "    sums = np.zeros(8,)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_of_larges = 0\n",
        "    with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          images = images.permute(0,3,1,2)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs = model(images)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          for i in range(len(predicted)):\n",
        "            correct += (predicted[i].item() in label_map_list[labels.long().reshape(labels.__len__())[i].item()])\n",
        "            sums[labels.long().reshape(labels.__len__())[i]]+=1\n",
        "            \n",
        "\n",
        "    print('Accuracy of the network on the test images: %d %%' % (100 * correct / total))\n",
        "    print(correct , \"  \" , total)\n",
        "    print(\"predicted: \",predicted)\n",
        "    print(\"GT: \", labels.long().reshape(labels.__len__()))\n",
        "    if correct > best:\n",
        "      best = correct\n",
        "      path = \"gdrive/My Drive/projectA/Models/color_small_model_resnet18\"\n",
        "      torch.save(model, path)\n",
        "      print(\"model saved...\")\n",
        "\n",
        "    if correct > best:\n",
        "      best = correct\n",
        "      path = \"gdrive/My Drive/projectA/Models/all_features_model\"\n",
        "      torch.save(model, path)\n",
        "    if (100 * correct / total) > 95:\n",
        "      break\n",
        "    if (100 * correct / total) > 92 and (100 * correct_1 / total_1)>72:\n",
        "      path = \"gdrive/My Drive/projectA/Models/all_features_model_densenet\"\n",
        "      torch.save(model, path)\n",
        "     \n",
        "  ##################################################################\n",
        "\n",
        "  ######################### Training section:     ##################\n",
        "  for k, (data, label) in enumerate(my_loader):\n",
        "      # Definition of inputs as variables for the net.\n",
        "      # requires_grad is set False because we do not need to compute the \n",
        "      # derivative of the inputs\n",
        "      data   = Variable(data,requires_grad=False)\n",
        "      label = Variable(label,requires_grad=False)\n",
        "      data = data.permute(0,3,1,2)\n",
        "      data = data.to(device)\n",
        "      label = label.to(device)\n",
        "      # Set gradient to 0.\n",
        "      optimizer.zero_grad()\n",
        "      # Feed forward.\n",
        "      pred = model(data)\n",
        "      pred = pred.to(device)\n",
        "\n",
        "      # Loss calculation.\n",
        "      loss = criterium(pred,label.view(-1))\n",
        "      # Gradient calculation.\n",
        "      loss.backward()\n",
        "\n",
        "      # Print loss every 10 iterations.\n",
        "      if k%30==0:\n",
        "          print('Loss {:.4f} at iter {:d}'.format(loss.item(),k))\n",
        "          \n",
        "\n",
        "      # Model weight modification based on the optimizer. \n",
        "      optimizer.step()\n",
        "   ##################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ETI55IOk81by",
        "colab": {}
      },
      "source": [
        "path_resnet = \"gdrive/My Drive/projectA/Models/all_features_model_resnet\"\n",
        "model_resnet = torch.load(path)\n",
        "path_densenet = \"gdrive/My Drive/projectA/Models/all_features_model_densenet\"\n",
        "model_densenet = torch.load(path)\n",
        "path_resnext = \"gdrive/My Drive/projectA/Models/all_features_model_resnext\"\n",
        "model_resnext = torch.load(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YmOWGNC_81b0",
        "colab": {}
      },
      "source": [
        "correct_tot = np.zeros(12,)\n",
        "total_tot = np.zeros(12,)\n",
        "correct_tot1 = np.zeros(12,)\n",
        "total_tot1 = np.zeros(12,)\n",
        "correct = 0\n",
        "total = 0\n",
        "correct_1 = 0\n",
        "total_1 = 0\n",
        "num_of_larges = 0\n",
        "with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          images, labels = data\n",
        "          images = images.permute(0,3,1,2)\n",
        "          images = images.to(device)\n",
        "          labels = labels.to(device)\n",
        "          outputs_resnet = torch.round(model_resnet(images).data + 0.473)\n",
        "          outputs_resnext = torch.round(model_resnext(images).data + 0.478)\n",
        "          outputs_densenet = torch.round(model_densenet(images).data + 0.476)\n",
        "#           _, predicted = torch.max(outputs.data, 1)\n",
        "          predicted = torch.round( (outputs_densenet + outputs_resnet + outputs_resnext)/float(3) )\n",
        "          for i,line in enumerate(labels):\n",
        "            for j,label in enumerate(line):\n",
        "               total_tot[j] += 1\n",
        "               correct_tot[j] += (predicted[i,j] == label).item()\n",
        "               if label == 1:\n",
        "                  total_tot1[j] += 1\n",
        "                  correct_tot1[j] += (predicted[i,j] == label).item()\n",
        "                  total_1 +=1\n",
        "                  correct_1 += (predicted[i,j] == label).item()\n",
        "          total += (labels.size(0) * labels.size(1) ) \n",
        "          correct += (predicted == labels).sum().item()            \n",
        "#           print(predicted.sum() )\n",
        "print('Accuracy of the network on the 1795 test images: %d %%' % (100 * correct / total))\n",
        "print(correct , \"  \" , total)\n",
        "print('Accuracy of the network on the 1 class only: %d %%' % (100 * correct_1 / total_1))\n",
        "print(correct_1 , \"  \" , total_1)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}